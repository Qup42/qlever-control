# Qleverfile for PubChem, use with https://github.com/ad-freiburg/qlever-control
#
# qlever get-data  # downloads+converts .gz files of size ~114 GB, takes ~5 h
# qlever index     # takes ~5 h and ~20 GB RAM on an AMD Ryzen 9 5900X
# qlever start     # starts the server (a few seconds)
#
# IMPORTANT NOTES:
#
# NOTE 1: The SPARQL endpoint at https://qlever.cs.uni-freiburg.de/pubchem also
# contains data from the following ontologies, which are very useful for
# resolving names of IRIs like `sio:SIO_000008` or `obo:IAO_0000412`, but which
# are not part of the PubChem RDF data. For the corresponding URLs, see
# https://github.com/ad-freiburg/qlever/issues/711#issuecomment-1200479401 .
# 
# bao bfo biopax-level3 chebi cheminf cito dublin_core_terms fabio go iao ncit
# obi pr ro sio skos so uo
#
# NOTE 2: The robots.txt file from https://ftp.ncbi.nlm.nih.gov currently
# disallows downloading the PubChem RDF data using `wget --recursive`. As a  
# workaround, the `GET_DATA_CMD` below uses `curl` to download the `void.ttl`
# and from that file extracts the URLs of the TTL files, which are then
# downloaded one by one. Alternatively, `wget --recursive` does work for the
# URL `ftp://ftp.ncbi.nlm.nih.gov/pubchem/RDF` (`ftp` instead of `https`).
#
# NOTE 3: Many of the TTL files have generic prefix definitions in the middle
# of the file, like `@prefix ns23: <http://identifiers.org/biocyc/ARACYC:>`.
# See https://github.com/ad-freiburg/qlever/issues/711#issuecomment-1197113953
# This is allowed by the standard, but very unusual. For use with QLever, the 
# `GET_DATA_CMD` therefore converts the TTL files to NT before indexing.
#
# NOTE 4: Many of the files (TTL as well as NT) contain invalid IRIs because
# spaces and braces are not properly escaped. The `GET_DATA_CMD` below
# percent-encodes each occurrence of a space, `[`, `]`, `{`, and `}` in an IRI.


[DEFAULT]
NAME = pubchem
DATE = 2024-02-03

[data]
GET_DATA_URL      = ftp://ftp.ncbi.nlm.nih.gov/pubchem/RDF
MAKE_GET_DATA_CMD = curl -s ${GET_DATA_URL}/void.ttl | grep -oP '${GET_DATA_URL}/.*?\.ttl\.gz' | grep -v "nbr[23]d" | while read URL; do echo "echo \"Processing $$URL ...\"; curl --silent --remote-time --output ttl.${DATE}/$$(basename $$URL) $$URL && docker run --rm -v $$(pwd)/ttl.${DATE}:/data stain/jena turtle --output=NT /data/$$(basename $$URL) | sed 's/> />\t/1; s/> />\t/1; s/ \.\$$/\t./' | awk 'BEGIN{FS=OFS=\"\t\"} {for (i = 1; i <= 3; i++) if (\$$i ~ /^<.*>\$$/) { gsub(/ /, \"%20\", \$$i); gsub(/\[/, \"%5B\", \$$i); gsub(/\]/, \"%5D\", \$$i); gsub(/{/, \"%7B\", \$$i); gsub(/}/, \"%7D\", \$$i); } print }' | sed 's/\t/ /g' | gzip -c > nt.${DATE}/$$(basename -s .ttl.gz $$URL).nt.gz"; done > pubchem.get-data-cmds.txt
GET_DATA_CMD      = mkdir -p ttl.${DATE} && mkdir -p nt.${DATE} && ${MAKE_GET_DATA_CMD} && cat pubchem.get-data-cmds.txt | parallel --line-buffer
INDEX_DESCRIPTION = PubChem RDF from ${GET_DATA_URL}, version ${DATE} (all folders except nbr2d and nbr3d)

[index]
FILE_NAMES        = nt.ONTOLOGIES/*.nt.gz nt.${DATE}/*.nt.gz
CAT_FILES         = zcat ${FILE_NAMES}
WITH_TEXT_INDEX   = false
STXXL_MEMORY      = 10G
SETTINGS_JSON     = { "languages-internal": [], "prefixes-external": [""], "ascii-prefixes-only": false, "num-triples-per-batch": 1000000 }

[server]
PORT                   = 7023
ACCESS_TOKEN           = ${NAME}_310129823
MEMORY_FOR_QUERIES     = 20G
TIMEOUT                = 120s

[docker]
USE_DOCKER              = false
QLEVER_DOCKER_IMAGE     = adfreiburg/qlever

[ui]
PORT   = 7000
CONFIG = pubchem
